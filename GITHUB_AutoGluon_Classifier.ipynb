{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e908e7-8ffd-47f8-acf1-f27f199d07c9",
   "metadata": {},
   "source": [
    "# Autogluon Classifier\n",
    "\n",
    "Install Autogluon and Bokeh(2.0.1) for Autogluon plots. Autogluon works with Python 3.8 to 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3bd45d-49d4-4d4c-82f6-9a4121b78052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63df418-385e-4eec-9425-96165f5a229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deals= pd.read_csv('Sample_Data_Deals2.csv')\n",
    "#Changbe column type from Object to Category for columns 3,4,5\n",
    "for col in ['Country', 'Industry', 'Deal Status']:\n",
    "    deals[col] = deals[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e77d3f9-3cb4-4794-9c27-d8f1a1a21d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   OrderID        100 non-null    object  \n",
      " 1   OrderQuantity  100 non-null    int64   \n",
      " 2   OrderValue     100 non-null    int64   \n",
      " 3   Country        100 non-null    category\n",
      " 4   Industry       100 non-null    category\n",
      " 5   Deal Status    100 non-null    category\n",
      "dtypes: category(3), int64(2), object(1)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "deals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4859d1-6f09-436f-942e-d81646748de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderQuantity</th>\n",
       "      <th>OrderValue</th>\n",
       "      <th>Country</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Deal Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>383</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>121</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>117</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>143</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>148</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderQuantity  OrderValue    Country       Industry Deal Status\n",
       "0            371         383     Canada     Technology         Won\n",
       "1            163         121     Canada        Finance         Won\n",
       "2            191         117  Australia  Manufacturing        Lost\n",
       "3            150         143  Australia  Manufacturing        Lost\n",
       "4            165         148  Australia  Manufacturing        Lost"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Order ID\n",
    "deals1 = pd.DataFrame(deals.iloc[:,1:])\n",
    "deals1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830f7e36-e68d-4430-8377-6206fc5b7591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderQuantity  OrderValue Country Industry Deal Status\n",
      "0            371         383       2        7           1\n",
      "1            163         121       2        2           1\n",
      "2            191         117       1        5           0\n",
      "3            150         143       1        5           0\n",
      "4            165         148       1        5           0\n"
     ]
    }
   ],
   "source": [
    "#Encoding categorical data, \n",
    "Country = {'Australia': 1, 'Canada':2, 'China':3, 'France':4, 'Germany':5}\n",
    "deals1['Country'] = deals1['Country'].map(Country)\n",
    "\n",
    "Industry = {'Energy':1, 'Finance':2, 'Government':3, 'Healthcare':4, 'Manufacturing':5, 'Retail':6, 'Technology':7}\n",
    "deals1['Industry'] = deals1['Industry'].map(Industry)\n",
    "\n",
    "dealstat= {'Won':1, 'Lost':0}\n",
    "deals1['Deal Status'] = deals1['Deal Status'].map(dealstat)\n",
    "\n",
    "print(deals1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fb7df1-3ae5-421b-bea2-d689c690d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderQuantity</th>\n",
       "      <th>OrderValue</th>\n",
       "      <th>Country</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Deal Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>383</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderQuantity  OrderValue Country Industry Deal Status\n",
       "0            371         383       2        7           1\n",
       "1            163         121       2        2           1\n",
       "2            191         117       1        5           0\n",
       "3            150         143       1        5           0\n",
       "4            165         148       1        5           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the dataset into an Autogluon Tabular Dataset\n",
    "df = TabularDataset(deals1)\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, shuffle=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7509af03-d92d-4b8e-a278-efb47891c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_model\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       15.23 GB / 31.64 GB (48.1%)\n",
      "Disk Space Avail:   367.45 GB / 475.50 GB (77.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"C:\\Users\\neogi\\Documents\\Python_venv\\autogluon_model\"\n",
      "Train Data Rows:    75\n",
      "Train Data Columns: 4\n",
      "Label Column:       Deal Status\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15592.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Country', 'Industry']\n",
      "\t\t('int', [])      : 2 | ['OrderQuantity', 'OrderValue']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Country', 'Industry']\n",
      "\t\t('int', [])      : 2 | ['OrderQuantity', 'OrderValue']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 60, Val Rows: 15\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 119.89s of the 119.89s of remaining time.\n",
      "\t0.2667\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 119.84s of the 119.84s of remaining time.\n",
      "\t0.1333\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 119.79s of the 119.79s of remaining time.\n",
      "\t0.6\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 119.14s of the 119.14s of remaining time.\n",
      "\t0.6\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 118.54s of the 118.53s of remaining time.\n",
      "\t0.4\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 117.60s of the 117.60s of remaining time.\n",
      "\t0.4\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 116.84s of the 116.83s of remaining time.\n",
      "\t0.6\t = Validation score   (accuracy)\n",
      "\t13.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 103.60s of the 103.59s of remaining time.\n",
      "\t0.5333\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 102.71s of the 102.70s of remaining time.\n",
      "\t0.4667\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 101.89s of the 101.89s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 101.13s of the 101.13s of remaining time.\n",
      "\t0.5333\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 100.53s of the 100.52s of remaining time.\n",
      "\t0.6\t = Validation score   (accuracy)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 99.59s of the 99.59s of remaining time.\n",
      "\t0.5333\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.89s of the 98.51s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 947.9 rows/s (15 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (15 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\Users\\neogi\\Documents\\Python_venv\\autogluon_model\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x21b8c40c7d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target column\n",
    "label = 'Deal Status'\n",
    "# Create a TabularPredictor object\n",
    "predictor = TabularPredictor(label=label, path='autogluon_model')\n",
    "TabularPredictor\n",
    "\n",
    "# Train the predictor\n",
    "predictor.fit(train_data=df_train, \n",
    "              time_limit=120) # Adjust time_limit (in seconds) as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e287af9-1572-4875-ab6a-1af32fd218eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model  score_test  score_val eval_metric  pred_time_test  \\\n",
      "0         CatBoost        0.72   0.600000    accuracy         0.00000   \n",
      "1   NeuralNetTorch        0.72   0.600000    accuracy         0.00000   \n",
      "2  NeuralNetFastAI        0.68   0.666667    accuracy         0.01058   \n",
      "\n",
      "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
      "0        0.00000  13.222656                  0.00000                 0.00000   \n",
      "1        0.01572   0.901883                  0.00000                 0.01572   \n",
      "2        0.00000   0.730980                  0.01058                 0.00000   \n",
      "\n",
      "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
      "0          13.222656            1       True          7  \n",
      "1           0.901883            1       True         12  \n",
      "2           0.730980            1       True         10  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set\n",
    "leaderboard = predictor.leaderboard(df_test, silent=True) \n",
    "print(leaderboard.head(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55260111-aeb7-4e6d-aca2-e4822356d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 4 features using 25 rows with 5 shuffle sets...\n",
      "\t0.49s\t= Expected runtime (0.1s per shuffle set)\n",
      "\t0.21s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OrderQuantity</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.081976</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>5</td>\n",
       "      <td>0.440789</td>\n",
       "      <td>0.103211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrderValue</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.082946</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>5</td>\n",
       "      <td>0.346786</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069111</td>\n",
       "      <td>-0.021111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance    stddev   p_value  n  p99_high   p99_low\n",
       "OrderQuantity       0.272  0.081976  0.000881  5  0.440789  0.103211\n",
       "OrderValue          0.176  0.082946  0.004503  5  0.346786  0.005214\n",
       "Industry            0.024  0.021909  0.035242  5  0.069111 -0.021111\n",
       "Country             0.000  0.000000  0.500000  5  0.000000  0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cfc5b27-0d10-4226-872b-e83a282b97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75    0\n",
      "76    0\n",
      "77    0\n",
      "78    0\n",
      "79    0\n",
      "80    0\n",
      "81    0\n",
      "82    1\n",
      "83    1\n",
      "84    1\n",
      "85    1\n",
      "86    1\n",
      "87    0\n",
      "88    0\n",
      "89    0\n",
      "90    1\n",
      "91    0\n",
      "92    1\n",
      "93    0\n",
      "94    1\n",
      "95    0\n",
      "96    0\n",
      "97    1\n",
      "98    1\n",
      "99    0\n",
      "Name: Deal Status, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predictions = predictor.predict(df_test)\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
